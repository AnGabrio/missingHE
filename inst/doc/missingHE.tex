\documentclass[]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\usepackage[margin=1in]{geometry}
\usepackage{hyperref}
\hypersetup{unicode=true,
            pdftitle={\textbf{missingHE}: Health Economic Evaluations with Missing Data},
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage{natbib}
\bibliographystyle{apa}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{{#1}}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{{#1}}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{{#1}}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{{#1}}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{{#1}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{{#1}}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{{#1}}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{{#1}}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{{#1}}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{{#1}}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{{#1}}}
\newcommand{\ImportTok}[1]{{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{{#1}}}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{{#1}}}}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{{#1}}}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{{#1}}}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{{#1}}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{{#1}}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{{#1}}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{{#1}}}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{{#1}}}}
\newcommand{\BuiltInTok}[1]{{#1}}
\newcommand{\ExtensionTok}[1]{{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{{#1}}}
\newcommand{\RegionMarkerTok}[1]{{#1}}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{{#1}}}}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{{#1}}}}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{{#1}}}}
\newcommand{\NormalTok}[1]{{#1}}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

%%% Use protect on footnotes to avoid problems with footnotes in titles
\let\rmarkdownfootnote\footnote%
\def\footnote{\protect\rmarkdownfootnote}

%%% Change title format to be more compact
\usepackage{titling}

% Create subtitle command for use in maketitle
\newcommand{\subtitle}[1]{
  \posttitle{
    \begin{center}\large#1\end{center}
    }
}

\renewenvironment{abstract}
{\begin{quote}
\noindent \rule{\linewidth}{.5pt}\par{\bfseries \abstractname.}}
{\medskip\noindent \rule{\linewidth}{.5pt}
\end{quote}
}


\setlength{\droptitle}{-2em}
  \title{\textbf{\Large missingHE: Health Economic Evaluations \\ with Missing Data}}
  \pretitle{\vspace{\droptitle}\centering\huge}
  \posttitle{\par \vspace*{0.5cm}}
  \author{\textnormal{\textbf{Andrea Gabrio}}\\
\textnormal{University College London}\\
\textnormal{Department of Statistical Science}\\
\textnormal{Gower Street, London, WC1E 6BT (UK)}\\
\textnormal{E-mail: \texttt {\href{mailto:ucakgab@ucl.ac.uk}{\nolinkurl{ucakgab@ucl.ac.uk}}}}}
  \preauthor{\centering\large\emph}
  \postauthor{\par}
  \date{}
  \predate{}\postdate{}

\usepackage{amsmath}
\usepackage{fancyhdr}
\usepackage{natbib}
\bibpunct{(}{)}{;}{a}{,}{,}
\usepackage{cite}
\pagestyle{fancy}
\fancyhf{}
\fancyhead[C]{missingHE; Economic Evaluation with Missing Data}
\fancyhead[R]{\thepage}
\thispagestyle{empty}
\usepackage{graphics}
\graphicspath{ {image/} }
\usepackage{bm}
\usepackage{float}
\usepackage{subfigure}
\usepackage{booktabs}
\usepackage[colorinlistoftodos]{todonotes}

\begin{document}
\maketitle
\begin{abstract}
This is my abstract.\\
\end{abstract}

\section{Introduction}\label{introduction}

Health economic evaluations based on individual-patient data are
generally characterised by a significant proportion of missing values in
the outcome variables. If these unobserved values are not appropriately
handled through suitable methods, they may bias results and possibly
mislead conclusions. This is particularly important for the modelling of
data in Cost-Effectiveness Analyses (CEAs), which typically show very
complex dependence structures between measures of clinical benefit,
e.g.~Quality-Adjusted Life Years (QALYs), and the costs associated with
the specific medical intervention considered.

In the \textit{statistical} literature, people deal with missing data
using different types of methods, such as Complete Case Analysis, Single
Imputation or Multiple Imputation. These are typically based on the
assumption that all the information required to obtain valid inferences
is embedded in the observed data. Such an assumption, however, is
not likely to hold in many practical cases. Thus, in all but the
simplest and least realistic examples, missing data analyses need to
explicitly incorporate some extra information from sources other than
the observed data. This amounts to using untestable assumptions,
obtained from the specific framework analysed or via expert opinions,
with the purpose to inform and guide the analysis.

The failure to correctly specify the uncertainty related to missingness
may have important consequences in terms of CEA decision output. This is
extremely relevant from the perspective of bodies responsible for
informing the provision of health care, such as the National Institute
for Health and Care Excellence (NICE) in the UK. Indeed, such analyses
may incorrectly suggest that a new intervention is cost-effective with
respect to some comparators. This, in turn, could lead to a
reimbursement of the new intervention by the public health care provider
(e.g.~NHS) that would not otherwise have occurred under more cautious
considerations of missing data assumptions. As a result, the final
resource allocation decision could be significantly affected.

Bayesian methods are well-suited to addressing decision-making problems,
such as that in economic evaluations \citep{Briggsb, Briggsc, Baioa}. By
taking a probabilistic approach, based on decision rules and available
information, they can explicitly account for all forms of uncertainty in
the decision process and obtain an ``optimal'' decision output. The
Bayesian approach naturally allows the formalisation and exploration of
plausible missingness assumptions to assess the robustness of the
results to a range of alternatives. This is possible because, under the
Bayesian paradigm, missing data can be thought of as parameters,
i.e.~unknown variables, whose uncertainty can be addressed via
suitably-defined prior distributions. Within this setting we can use a
\textit{principled} approach to missingness that embeds critical
thinking about missing data assumptions and handles complex dependence
structures between variables.

With this in mind, the objective of this work is to develop a suite of
functions and tools for the freely available statistical software R,
specifically designed to allow the incorporation of external information
to explore alternative plausible missingness assumption scenarios.

\section{The R package of missingHE}\label{the-r-package-of-missinghe}

\textbf{MissingHE} is a package designed to aid in the process of
economic evaluations in Health Economics
in the presence of missing data in the outcome variables. The Bayesian approach is used 
to assess the uncertainty induced by the missing data and underpinning decision-making problems,
from the perspective of decision makers. In fact, \textbf{missingHE} can be considered a wrapper for some
other R packages. The first two, \textbf{R2OpenBUGS} \citep{GelmanBUGS}
and \textbf{R2jags} \citep{Su}, are programs for simulation from
Bayesian hierarchical models using Markov chain Monte Carlo (MCMC)
methods that are based on the \texttt{BUGS} modelling language. The
third, \textbf{BCEA} \citep{BCEA}, is used to produce an economic
evaluation output from the posterior inference generated via the
software \texttt{OpenBUGS} or \texttt{JAGS}. The package also relies on
other packages such as \textbf{ggplot2} \citep{Wickham},
\textbf{gridExtra} \citep{Auguie}, \textbf{ggthemes} \citep{Arnold},
\textbf{mcmcplots} \citep{Curtis} and \textbf{ggmcmc} \citep{Marin},
mainly for graphics purposes.

\subsection{Economic Evaluations: A Bayesian
approach}\label{economic-evaluations-a-bayesian-approach}

With respect to the context analysed, a Bayesian approach has several convenient aspects. For
example, health economic evaluations are typically based on complex
models, often made by several (correlated) modules, which may be
informed by different and diverse sources of evidence. Thus, a Bayesian
approach can be beneficial to propagate the uncertainty underlying
all model parameters in a principled way. This is also particularly
relevant in terms of Probabilistic Sensitivity Analysis (PSA), e.g.~the
practice of assessing the impact of parameters uncertainty on the
decision-making process. PSA is usually based on a simulation approach
to characterise the uncertainty of the model parameters, a
fundamentally Bayesian operation. On the other hand, Bayesian models
require the specification of suitable prior distributions that are
consistent with the information available, and can
be computationally intensive. However, given the advantages Bayesian
models can offer in standard modelling settings we build the whole
economic modelling under a Bayesian framework and take full advantage of the
flexibility provided by MCMC estimation \citep{Brooks}.

\subsection{Modellig Missing Data in Economic
Evaluations}\label{modellig-missing-data-in-economic-evaluations}

Missing data do not only impact analyses because of a reduced sample
size, possibly affecting efficiency of the estimates, but they also
prevent the use of standard complete-data methods. Nonrespondents can be
systematically different from respondents in terms of characteristics or
outcomes. This could lead to biases in the results that are difficult to
eliminate, possibly leading to the (often implicit) formulation of
unrealistic missingness assumptions. This is particularly true when, as
often happens in clinical studies, reasons for missingness are ignored
or not properly recorded. As a result, the statistical and economic
analysis will be impaired because assumptions about unobserved data will
be forced by the lack of available information about the missing values.

Finally, it is important to stress that, in the presence of missingness,
any analysis method implies some assumptions about the missing values,
which cannot be ultimately tested from the data at hand. As it has been
pointed out \citep{Molenberghsb}, a convenient way for broadly
identifying the severity of the missingness problem is whether reasons
for nonresponse are related or not to the outcome of interest. If there
is no relation, then missingness should not hugely complicate the
analysis, while if such a relationship exists it is plausible for
nonrespondents to be systematically different from respondents. This may
lead to biases that can distort the results and, within CEAs, lead to
the approval of a treatment option that in fact is not cost-effective.

\subsection{\texorpdfstring{Missing Data
Mechanism\label{MDM}}{Missing Data Mechanism}}\label{missing-data-mechanism}

When analysing partially observed data, it is essential to investigate
the possible reasons behind missingness. This formally translates
into an \textit{assumed} missing data mechanism \citep{Rubina} that is
linked to the data generating process, a key concept to address
missingness in a ``principled'' way. We specifically refer to
``principled'' methods for missing data as those based on a well-defined
statistical model for the complete data, and explicit assumptions about
the missing value mechanism.

We consider a sample of \(i=1,\ldots,n\) individuals for whom the
relevant outcome is indicated as \(y_i\), which is unobserved for some
individuals. Typically, trial data also include a set of \(J\)
covariates \(\bm{x}_i=(x_{1i},\ldots,x_{Ji})\), e.g.~sex, age or
co-morbidities. While in general these may be partially or fully
observed, in this section we consider only the latter case. In addition,
we define a missingness indicator \(m_{i}\) taking value 1 if the
\(i-\)th subject is associated with missing outcome and 0 otherwise.

This setting can be modelled using two sub-models, or ``modules''. The
first module is the missing data mechanism, denoted as
\textit{Model of Missingness} (MoM). It describes a probability
distribution for \(m_{i}\), as a function of some unobserved parameters
\(\pi_{i}\) and \(\delta\), defining the probability of missingness in
the outcome variable \(y_{i}\). The second module is the data generating
process of the outcome variable, denoted as \textit{Model of Analysis}
(MoA). This contains the main parameters of interest (e.g.~the
population average costs and benefits) and describes a probability model
for the outcome \(y_{i}\). As a general example, we can think of a
simple regression model where \(y_i\sim\mbox{N}(\mu_i,\sigma)\), and
\(\mu_{i} = \beta_0+\beta_1 x_i\). In this case, the parameters of the
MoA are the regression coefficients \(\bm\beta=(\beta_0,\beta_1)\)
representing respectively the intercept and the slope, and the
individual standard deviation \(\sigma\).

The most accepted classification of missingness mechanisms is given by
\citep{Rubina} and is based on three classes, according to how the
missingness probability in the MoM is modelled. A simple graphical
representation of the three classes is provided in Figure~\ref{F1}. Variables
and parameters are denoted by nodes of different shapes and colours
according to their nature. Parameters (\(\beta_0\), \(\beta_1\),
\(\sigma\), \(\delta\)) are represented through grey circles.
``Logical'' quantities such as \(\mu_{i}\) and \(\pi_{i}\), which are
defined as a function of other parameters, are denoted by a double
circle notation. Fully observed variables (\(m_{i}\)) are represented
with a white circle while partially observed variables (\(y_{i}\)) are
denoted by a darker grey circle. Finally, we show covariates (\(x_{i}\))
as white squares to indicate that they are fully observed and not
modelled. Rounded rectangles are used to show the extent of the two
modules in terms of variables/parameters included. Arrows show the
relationships between the nodes, with dashed and solid lines indicating
logical functions and stochastic dependence, respectively.

\begin{figure}[H]
\centering
\subfigure[Missing Completely At Random
(MCAR)]{\label{fig:a}\includegraphics[width=60mm]{pic_MCAR}}
\subfigure[Missing At Random (MAR)]{\label{fig:b}\includegraphics[width=60mm]{pic_MAR}}\\
\subfigure[Missing Not At Random (MNAR)]{\label{fig:b}\includegraphics[width=60mm]{pic_MNAR}}
\caption{Graphical representation of Rubin's missing data mechanism classes, namely (a) MCAR, (b)
MAR and (c) MNAR. Variables and parameters are represented through nodes of different shapes and
colours. Parameters are indicated by grey circles with logical parameters defined by double circles, while predictor variables are assumed fixed and drawn as white squares. Fully observed variables are denoted by white circles, partially observed variables by darker grey circles. Nodes are related to each other through dashed and solid arrows which respectively represent logical functions and stochastic dependence. MoA=Model of Analysis, MoM=Model of Missingness.}\label{F1}
\end{figure}

The missing data mechanism specifies a probability model for the
distribution of \(m_{i}\) conditional on all other variables, broadly
distinguished, according to Rubin's classification, into three classes.

Figure~\ref{F1} (a) illustrates the class of `Missing Completely At Random'
(MCAR), in which the probability of missingness is fully independent of
any other partially or fully observed variable. Consequently, in Figure
1 (a) MoA and MoM are not connected and \(\pi_{i}\) does not depend on
any quantity in the MoA. This amounts to assuming that there is no
systematic difference between partially and fully observed individuals
in terms of the outcome \(y_{i}\). In other words, in this case we would
be assuming that observed cases are a representative sample of the full
sample.

Figure~\ref{F1} (b) shows a case of `Missing At Random' (MAR), in which the
missingness probability may depend on a fully observed variable. As a
result, MoA and MoM are connected by means of the predictor variable
affecting both the mechanisms generating \(y_{i}\) and \(m_{i}\).
Because of this relationship, the partially observed cases are
systematically different from the fully observed cases; crucially,
however, the difference is fully captured by \(x_{i}\).

Figure~\ref{F1} (c) provides an example of `Missing Not At Random' (MNAR). This
is characterised by dependence of the probability of missingness on both
the partially and fully observed variables. Thus, in Figure 1 (c)
\(\pi_{i}\) depends on both the fully observed predictor \(x_{i}\) and
the partially observed outcome \(y_{i}\). This means that the difference
between fully and partially observed cases still depends on the missing
values, even after taking \(x_{i}\) into account. Therefore it is
necessary to make more structured assumptions about this relationship
that go beyond the information contained in the data.

\subsection{Selection Models}\label{selection-models}

Independently of the setting analysed, if MCAR is not credible, there is
one important issue that should always be considered in conducting
analysis with missing data: one cannot definitively distinguish between
MAR and MNAR models. The data alone do not provide all the information
necessary to make this choice and, at the same time, different MNAR
models can provide identical fits to the observed data. However, they
may have quite different implications for the unobserved data, leading
to different conclusions \citep{Molenberghsb}. Therefore, it becomes
crucial to explore the sensitivity of the results with respect to
different missing data assumptions and quantify results' uncertainty.
What is generally recommended is to set MAR as the reference assumption
and then explore different MNAR departures. However, the base-case
analysis should be primarily defined based on the available state of
knowledge in the given setting. When informative missingness is thought
to be the most realistic scenario, setting-specific MNAR
assumptions should be set as the reference case, with suitably-defined
departures being explored in \textit{Sensitivity Analysis} (SA).
Usually, SA for nonignorable/informative models is implemented through
advanced statistical methods, which can explicitly model a MNAR
mechanism. One popular technique is the \textit{Selection Model}
approach \citep{Molenberghsb, Daniels, Masona}.

To represent the application of selection models we consider a simple
example. We assume a data set comprising a partially observed response
variable \(y\), the corresponding missing data indicator vector \(m\),
and a fully-observed covariate \(x\). Under the SM approach, the joint
distribution \(p(y,m)\) is factored as the product of the marginal
distribution \(p(y)\) and the conditional distribution \(p(m \mid y)\).

\begin{equation}\label{eqSM}
p(y,m\mid x,\bm{\theta}^{MoA},\bm{\theta}^{MoM})=p(y\mid x,\bm{\theta}^{MoA})p(m\mid y,x,\bm{\theta}^{MoM})
\end{equation}

where, \(\bm{\theta}^{MoA},\bm{\theta}^{MoM}\) are respectively the set
of parameters associated with the MoA and that associated with the MoM,
respectively. In Equation (\ref{eqSM}) we need to specify the complete
data model for the response, so that the probability of nonresponse is
modelled conditionally on the possibly unobserved outcomes. Model
identifiability comes from some parametric assumption about \(p(y)\).
This will implicitly set up the relationship between parameters indexing
the distribution of the observed and unobserved cases, together with
some unverifiable assumptions on the specific form of \(p(m\mid y)\).

To show how to build a selection model we use the simplified framework
with only one partially observed outcome variable \(y\). We then need to
jointly model \(p(y,m\mid x,\bm{\theta}^{MoA},\bm{\theta}^{MoM})\) by
specifying the two different modules associated with the observed and
missingness processes (MoA and MoM), based on the selection model
factorisation. While the MoA specification depends on the main
parameters of interest and the setting-specific research question
involved, the MoM can have a more generalised structure.

\subsubsection{\texorpdfstring{Model of
Analysis\label{MoA}}{Model of Analysis}}\label{model-of-analysis}

Under a Selection Model, we need to specify the form of the probability
distribution assumed in the MoA to describe the uncertainty in the
observed outcome variables, i.e.~effects and costs. It is good practice
to test a set of (more or less) plausible parametric models for the
outcome data according to their characteristics and support.

In general terms, we can specify the vector of relevant parameters as
\(\bm{\theta}^{MoA}=(\mu,\alpha)\). Specifically, \(\mu\) and \(\alpha\)
respectively represent a \textit{location} parameter, which typically
indicates the mean of the probability distribution, and a (set of)
\textit{ancillary} parameter(s), which describes the shape or variance
of the distribution.

While it is possible for both \(\mu\) and \(\alpha\) to explicitly
depend on some covariates \(\bm{x}\), usually the formulation is
simplified to assume that these only affect directly the location
parameter. In addition, we typically use a linear formulation

\begin{equation}\label{meanreg}
\mu=\beta_{0}+\sum_{j=1}^{J}{\beta_{j}x_{ij}}
\end{equation}

to model the location parameter. In a full Bayesian setting, the
parameters are directly modelled using a prior probability distribution,
which is updated by the observed data into a posterior. It is this
posterior distribution that is the object of the inferential process.
For instance, we can assign the following priors to the regression coefficients:
\(\bm{\beta}=(\beta_{0},\beta_{1},\ldots,\beta_{J}) \overset{iid}\sim \mbox{Normal}(\mu_{\beta},\alpha_{\beta})\).
If no covariate data are provided then this would correspond to define a
prior directly on the marginal mean parameter \(\mu\), whose
specification will depend on the support for the given MoA distributions
assumed.

Note that \textbf{missingHE} expands any categorical covariates to a set
of dummy variables: so if a covariate has four categories, in line with
R notation, \textbf{missingHE} considers three binary indicators. Thus
the profile (0,0,0) indicates the first (reference) category, while the
profiles (1,0,0), (0,1,0) and (0,0,1) indicate the second, third and
fourth category, respectively. In \textbf{missingHE}, the number of
covariates J depends on this full expansion of the design matrix.

By default, \textbf{missingHE} assumes \(\mu_{\beta}=0\) and
\(\alpha_{\beta}=1000\). This amounts to specifying a ``minimally
informative" prior on the regression coefficients that determine the
location parameter; in other words, we are not including strong prior
information in this aspect of our model. When genuine prior knowledge is
present, it is possible to modify these priors to encode the information
in the model formulation. As for the ancillary parameter, the choice of
prior depends on the specification of the probability distribution
selected to model the data. Table 1 shows a summary of the models
directly implemented in \textbf{missingHE}. In each, by default, we
specify minimally informative priors on all the relevant parameters.

\begin{table}[H]
 \centering
 \resizebox{\linewidth}{!}{%
 \begin{tabular}{cccc} \toprule
Data Model & Location Parameter & Ancillary Parameter & \textbf{missingHE} name\\ \midrule
\multicolumn{4}{l}{\bf{Shared Distributions}}\\ [1.5em]
$e_{i};c_{i}\sim \mbox{Normal}(\mu,\alpha)$ & Mean: $\mu \sim \mbox{Normal}(0,10000)$ & log-SD: $\alpha \sim \mbox{Uniform}(-5,10)$ & norm\\[1.5em] 
\multicolumn{4}{l}{\bf{Effect Distributions}}\\ [1.5em]
$e_{i}\sim \mbox{Beta}(\mu,\alpha)$ & Mean: $\mu \sim \mbox{Uniform}(0,1)$ & SD: $\alpha \sim \mbox{Uniform}(0,\sqrt{\mu(1-\mu)})$ & beta\\ [1.5em]
\multicolumn{4}{l}{\bf{Cost Distributions}}\\ [1.5em]
$c_{i}\sim \mbox{Gamma}(\mu,\alpha)$ & Mean:  $\mu \sim \mbox{Uniform}(0,10000)$ & SD: $\alpha \sim \mbox{Cauchy}(0,2.5)\mbox{I}(0,)$ & gamma\\ \bottomrule
     \end{tabular}}\caption{A list of the distributions supported by \textbf{missingHE} for the effect $(e_{i})$ and cost $(c_{i})$ variables in the MoA with the default weakly informative prior forms assumed. The names on the right-hand side of the table represent the character names in \textbf{missingHE} notation to indicate the corresponding distribution.}
  \end{table}\label{T1}

To provide user-defined prior distributions for the location and
ancillary parameters we need to create objects having names
\texttt{mu.prior.e} and \texttt{alpha.prior.e} for the effects and
\texttt{mu.prior.c} and \texttt{alpha.prior.c} for the costs,
respectively. These objects must contain the hyperprior values defined
by the user. For example, assuming to model both outcomes by a Normal
distribution, the default priors for \(\mu\) and \(\alpha\) for the
effects, for instance, can be overwritten by creating the two objects
\texttt{mu.prior.e} and \texttt{alpha.prior.e} containing the desired
values. Then, these values are supplied to the main function \texttt{run\_model} as
additional arguments (more on this later). In R this can be perfomed as
follows:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#hyperprior mean and standard deviation for the location parameter}
\NormalTok{a<-}\DecValTok{0}
\NormalTok{b<-}\DecValTok{1}
\NormalTok{mu.prior.e<-}\KeywordTok{c}\NormalTok{(a,b)}
\CommentTok{#hyperprior lower and upper bound for the ancillary parameter}
\NormalTok{l<--}\DecValTok{5}
\NormalTok{u<-}\DecValTok{5}
\NormalTok{alpha.prior.e<-}\KeywordTok{c}\NormalTok{(l,u)}
\end{Highlighting}
\end{Shaded}

The hyperprior values for both \(\mu\) and \(\alpha\) must be chosen
according to the specific model structure assumed by \textbf{missingHE}
as different outcome distributional assumptions may lead to different
types of prior forms. The types of prior forms assumed for the location
and ancillary parameters for alternative MoA specifications are shown in
Table 1.

If covariate data are incorporated in the model, then the location
paraemter \(\mu\) is replaced by the expression of Equation
(\ref{meanreg}) and hyperprior values should be supplied for each
regression coefficient parameter
\(\bm{\beta}=\left(\beta_{0},\ldots,\beta_{J}\right)\). To notice that
in this case all coefficient prior distributions are by default
weakly-informative normal distributions except the baseline regression
parameter \(\beta_{0}\) that is considered and modelled equivalently to
the marginal mean \(\mu\).

For example, if we assume to have two covariates that we want to include
in the model, the user-provided hyperprior values for all the
regression coefficient parameters can be specified by creating two
objects having names \texttt{beta0.prior.e} and \texttt{beta.prior.e}
for the effects and \texttt{beta0.prior.c} and \texttt{beta.prior.c} for
the costs, respectively. These objects must contain the user-provided
hyperprior values for the marginal mean and covariate specific
coefficient parameters, respectively. For the latter, the hyperprior
values supplied will be applied equivalently to all covariate-specific
parameters.

Assuming again a bivariate normal distribution for \((e_{i},c_{i})\), in
R the default priors for the mean regression coefficient paraemters for
the effects, for example, can be performed as follows:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#hyperprior mean and standard deviation for the marginal mean parameter}
\NormalTok{a<-}\DecValTok{0}
\NormalTok{b<-}\DecValTok{1}
\NormalTok{beta0.prior.e<-}\KeywordTok{c}\NormalTok{(a,b)}
\CommentTok{#hyperprior mean and standard deviation for the regression coefficient parameters}
\NormalTok{c<-}\DecValTok{0}
\NormalTok{d<-}\DecValTok{1}
\NormalTok{beta.prior.e<-}\KeywordTok{c}\NormalTok{(c,d)}
\end{Highlighting}
\end{Shaded}

\subsubsection{\texorpdfstring{Model of
Missingness\label{MoM}}{Model of Missingness}}\label{model-of-missingness}

A common procedure to build the MoM module under a Selection Model
approach assigns a Bernoulli probability distribution to the missing
data indicator \(m_{i} \sim \mbox{Bernoulli}(\pi_{i})\), where
\(\pi_{i}\) is the parameter specifying the probability of \(y_{i}\)
being missing, with either \(y_{i}=e_{i}\) or \(y_{i}=c_{i}\). At this
point, we can model the missingness probability \(\pi_{i}\) in a variety
of ways based on the assumptions we would like to make about the missing
data mechanism. Here, we present a general model specification for a
MNAR missingness mechanism that includes the MAR and MCAR assumptions as
special cases.

\begin{equation}\label{eqSM2}
\mbox{logit}(\pi_{i})=\gamma_{0}+\gamma_{j}x_{ij}+\delta y_{i}
\end{equation}

where \(\bm{\theta}^{MoM}=(\gamma_{0},\gamma_{j},\delta)\), with
\(j=1,\ldots,J\) being the number of covariates. The ``log odds''
\(\mbox{logit}(\pi)\) is computed as
\(\mbox{logit}(\pi_{i})=\log \left({\frac{\pi_{i}}{1-\pi_{i}}}\right)\).

The logistic regression is just a common transformation that is used to
rescale the parameter space of \(\pi_{i}\) from \((0,1)\) to
\((-\infty,+\infty)\) so to include in the regression any variable upon
which the missingness probability may depend. More specifically:

\begin{itemize}
 \item{$\gamma_{0}$ is a logistic regression baseline parameter that does not depend on any variable. When $\gamma_{j}=\delta=0$, the model assumes MCAR, as missing values in the outcome $y_{i}$ will be imputed  independently on any variable in the MoA.}
 \item{$\gamma_{j}$ represents the impact on the probability of missingness in $y_{i}$ of the fully observed covariate $x_{ij}$. When $\delta=0$, the model assumes MAR, as missing values in the outcome $y_{i}$ will be imputed conditionally on $x_{ij}$.}
\item{$\delta$ represents the impact on the probability of missingness in $y_{i}$ of the possibly unobserved values in $y_{i}$. The model now assumes MNAR, as missing values in the outcome $y_{i}$ will be imputed conditionally on themselves (given the extra information brought into the model to specify this conditional dependence).}
\end{itemize}

As with respect to the prior distributions of the MoM parameters, as for
the MoA parameters, they can all be provided by the users while the
default values are chosen with the aim to limit the impact of possible
prior informative content on posterior inferences. Table 2 shows a
summary of the default settings for the logistic regression parameters
based on the class of MoMs that can be indicated in \textbf{missingHE}
(same structure is assumed for both effects and costs).

\begin{table}[H]
 \centering
 \resizebox{\linewidth}{!}{%
 \begin{tabular}{cccc} \toprule
Missingness Model & Logistic Regression Parameter  & \multicolumn{2}{c}{\textbf{missingHE} name}\\ \midrule
\multicolumn{2}{c}{} & \textbf{effects} & \textbf{costs} \\ [0.5em]
MCAR & Baseline parameter: $\gamma_{0} \sim \mbox{Logisitc}(0,1)$ & gamma0.prior.e & gamma0.prior.c\\[1.5em] 
MAR & Covariate(s) parameter: $\gamma_{j} \sim \mbox{Normal}(0,1)$ & gamma.prior.e & gamma.prior.c\\ [1.5em]
MNAR & MNAR parameter:  $\delta \sim \mbox{Normal}(0,1)$ & delta.prior.e & delta.prior.c\\ \bottomrule
     \end{tabular}}\caption{A list of the different MoM parameter specifications assumed in \textbf{missingHE} and the default prior distributions assigned. The names on the right-hand side of the table represent the name to be used in \textbf{missingHE} to provide user-defined priors in a similar way to what previously shown for the location and ancillary MoA parameters.}
  \end{table}

For the MNAR parameter \(\delta\) a similar prior to those used for
\(\gamma_{j}\) is assumed for convenience. However, because such
parameter expresses the dependence of the MoM on the missing data, then
no actual ``minimally informative" prior exist as there are no data able
to inform its estimation. As a result, all choices may end up to have a
quite significant impact on posterior results, and should be selected
according to the context specific missingness information available. The
exploration of plausible alternative prior values is necessary in a MNAR
setting, as the only way to assess the robustness of posterior
inferences to plausible alternative missingness scenarios. This is
possible in \textbf{missingHE} by directly providing the values for the
hyperparameter \(\delta\) and compare how results change across
different choices.

Selection Models allow to directly model the target distribution of the
complete data. This has the advantage to straightforwardly formulate
assumptions about the nonresponse mechanism. The drawback is how we can
translate these assumptions into assumptions on the distribution of the
missing data. Indeed, model identification depends on assumptions on the
distribution of \(y_{i}\) (often difficult to check) and on the form of
the missingness model (on which unverifiable assumptions have to be
made). Moreover, once the model is specified, all parameters are
identified by the observed data and model assumptions. The best way to
assess the impact of missingness on results is to vary distributional
assumptions in the MoA and the form of the MoM. Independently on the
method chosen, it must be noticed that all models have to rely on some
arbitrary assumptions in order to be identified. This means that
inference is possible only after some unverifiable assumptions about the
missingness process have been formulated. Within this context,
sensitivity analysis becomes extremely important in order to assess the
robustness of the conclusions by reporting the results obtained under a
range of plausible assumptions.

\subsection{\texorpdfstring{Example
\label{ex}}{Example }}\label{example}

In the following, we use a running example to present the features of
\textbf{missingHE}. Suppose that the user has a suitable dataset,
perhaps obtained from a trial, in which data for each individual are
recorded for the effectiveness and cost variables as well as for an arm
indicator specifying whether the individual to whom the data refer
belongs in the control or the active treatment arm of the trial. Of
course, other variables may be observed, e.g.~relevant covariates, such
as sex, age or co-morbidity. Both outcome variables can have missing
values while no unobserved values should be observed for the covariates
as \textbf{missingHE} can only deal with missingness in the outcomes.

Assume that the data are available in the R workspace as a data-frame
(say, \texttt{data}) that can be partially visualised using the
following command

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{rbind}\NormalTok{(}\KeywordTok{head}\NormalTok{(data),}\KeywordTok{tail}\NormalTok{(data))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##             e         c t
## 1   0.5262802  88.84761 1
## 2   0.4168671  71.16754 1
## 3   0.7516885 110.13573 1
## 4   0.9547645  77.74878 1
## 5          NA        NA 1
## 6          NA        NA 1
## 245 0.2422857 116.66148 2
## 246 0.6418311 107.61227 2
## 247        NA        NA 2
## 248        NA        NA 2
## 249 0.5444913 127.72288 2
## 250        NA        NA 2
\end{verbatim}

The dataset consists of 250 individuals in total, grouped in two arms
(here arm = 1 indicates the controls and arm = 2 indicates the active
treatment).

\section{\texorpdfstring{Bayesian Analysis via
JAGS/BUGS\label{Bayes}}{Bayesian Analysis via JAGS/BUGS}}\label{bayesian-analysis-via-jagsbugs}

Cost-Effectvieness Models are implemented in \textbf{missingHE} using
Bayesian specific program software languages, namely \texttt{BUGS} or
\texttt{JAGS}, which are called from two corresponding R packages,
\textbf{R2OpenBUGS} and \textbf{R2jags}. \texttt{BUGS} (Bayesian
inference Using Gibbs Sampling) \citep{Lunn} is a software package for
performing Bayesian inference Using Gibbs Sampling. The user specifies a
statistical model, of (almost) arbitrary complexity, by simply stating
the relationships between related variables. The software includes an
expert system, which determines an appropriate MCMC \citep{Brooks}
(Markov chain Monte Carlo) scheme (based on the Gibbs sampler) for
analysing the specified model. \texttt{JAGS} \citep{Plummer} (Just
Another Gibbs Sampler) by Martyn Plummer is an open source program which
was developed independently of the BUGS project. JAGS uses essentially
the same model description language of \texttt{BUGS} but it has been
completely~re-written.

To illustrate how \textbf{missingHE} interfaces with these programs we
continue the example in Section \ref{ex} and we assume for simplicity to
assign a bivariate independent normal distribution to the effect and
cost variables \((e_{i},c_{i})\) in the MoA. With respect to the MoM we
assume a MNAR structure for the effects while we keep a MCAR assumption
for the costs in both treatment arms \(t=1,2\). In \textbf{missingHE} we
can implement the model using the \texttt{run\_model} function in the
following way.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{12345}\NormalTok{)}
\NormalTok{model<-}\KeywordTok{run_model}\NormalTok{(}\DataTypeTok{data=}\NormalTok{data,}\DataTypeTok{dist_e=}\StringTok{"norm"}\NormalTok{,}\DataTypeTok{dist_c=}\StringTok{"norm"}\NormalTok{,}\DataTypeTok{type=}\StringTok{"MNAR_eff"}\NormalTok{,}\DataTypeTok{stand=}\OtherTok{FALSE}\NormalTok{,}\DataTypeTok{ind=}\OtherTok{TRUE}\NormalTok{,}
                 \DataTypeTok{program=}\StringTok{"JAGS"}\NormalTok{,}\DataTypeTok{forward=}\OtherTok{FALSE}\NormalTok{,}\DataTypeTok{prob=}\KeywordTok{c}\NormalTok{(}\FloatTok{0.05}\NormalTok{,}\FloatTok{0.95}\NormalTok{),}\DataTypeTok{n.chains=}\DecValTok{2}\NormalTok{,}\DataTypeTok{n.iter=}\DecValTok{20000}\NormalTok{,}
                 \DataTypeTok{n.burnin=}\KeywordTok{floor}\NormalTok{(}\DecValTok{20000}\NormalTok{/}\DecValTok{2}\NormalTok{),}\DataTypeTok{inits=}\OtherTok{NULL}\NormalTok{,}\DataTypeTok{n.thin=}\DecValTok{1}\NormalTok{,}\DataTypeTok{save_model=}\OtherTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The \texttt{run\_model} function takes as input four compulsory
arguments.

\begin{itemize}
\item
  The first is the data frame \texttt{data} and contains the economic
  evaluation data to analyse in the format described in Section
  \ref{ex}.
\item
  The second is \texttt{type}, which indicates the class of missingness
  mechanism assumed by the user. The types allowed are
  (``MCAR'',``MAR'',``MNAR'',``MNAR\_eff'',``MNAR\_cost'') and represent
  the different possible mechanism specifications. Because we assume a
  MNAR structure only for the effects, the class we need to specify for
  this example is ``MNAR\_eff'' that defines a MNAR mechanism for the effects
  while keeping MCAR/MAR for the costs. For all classes, except from
  ``MCAR'', whenever \texttt{data} contains some covariate data, these
  are automatically included in the model through a mean linear
  regression in the MoA and added to the logistic regression in the MoM,
  after the corresponding covariate specific coefficients have been
  generated.
\item
  The third and fourth inputs are the distributions assumed for the
  effect and cost variables in the MoA, \texttt{dist\_e} and
  \texttt{dist\_c}, respectively. The distributions that are available
  in \textbf{missingHE} and their parameterisations are presented in
  Table 1. In this example we assume a normal distribution for both
  outcomes, indicated in \textbf{missingHE} by the string ``norm''.
\end{itemize}

The other arguments are optional and are related to different aspects of
the model. Among the most important optional arguments there are:

\begin{itemize}
\item
  \texttt{stand} (valid only for bivariate normal) specifies whether
  outcome variables should be modelled on their standardised
  (\texttt{TRUE}) or natural scale (\texttt{FALSE}). If scaled,
  variables are standardised using the corresponding sample mean and
  standard error so to have scaled mean of \(0\) and standard error of
  \(0.5\), following Gelman's recommendations \citep{Gelmanp}. The
  default value is \texttt{FALSE}.
\item
  \texttt{ind} (valid only for bivariate normal) specifies whether
  outcome variables are modelled independetly (\texttt{TRUE}) or jointly
  (\texttt{FALSE}). The default value is \texttt{TRUE}.
  \item
  \texttt{transf} (valid only for beta and gamma distribution) specifies on which scale effect or cost variables are modelled.
  If no values is specified, outcomes are modelled on their natural scale. Alternative choices
  are the log-scale for costs (\texttt{log}) and the logit scale for effects (\texttt{logit}).
\item
  \texttt{program} specifies which software program to use to run the
  model, i.e. \texttt{JAGS} for JAGS or \texttt{BUGS} for OpenBUGS.
\item
  \texttt{forward} specifies whether the model should be run in forward
  sampling mode (\texttt{TRUE}), i.e.~sampling from the prior without
  considering the data, or in standard samping mode (\texttt{FALSE}).
  The default value is \texttt{FALSE}.
\item
  \texttt{prob} must be a vector of length two containing the lower and
  upper bounds for the credible intervals associated with the posterior
  distribution of the imputed outcome data. Default values specify a
  95\%~CI.
\item
  \texttt{n.chains} defines the number of Markov chains to use in the
  MCMC sampler.
\item
  \texttt{n.burnin} defines the warmup phase for the MCMC iterations
  that is discarded.
\item
  \texttt{n.iter} defines the number of total MCMC iterations to use per
  each chain (included the burnin).
\item
  \texttt{n.thin} defines the thinning rate.
\item
  \texttt{inits} is a list with \texttt{n.chains} elements; each element
  of the list is itself a list of starting values for the model, or a
  function creating (possibly random) initial values. If
  \texttt{inits=NULL}, either \texttt{BUGS} or \texttt{JAGS} will
  automatically generate the initial values for the parameters.
\item
  \texttt{save\_model} specifies whether the \texttt{txt} file
  containing the \texttt{BUGS} model should (\texttt{TRUE}) or should
  not (\texttt{FALSE}) be saved in the current working directory. The
  default value is \texttt{FALSE}.
\end{itemize}

Behind the scenes \textbf{missingHE} translates the model information
provided in the inputs of \texttt{run\_model} and writes a txt file in a
form that can be read by either \texttt{BUGS} or \texttt{JAGS}. For the
example considered, the corresponding model specification can be more
easily represented as follows.

\begin{align*}
\hspace*{-5cm}
\mbox{\textbf{Model of Analysis (MoA)}}\\
e_{it}&\sim \mbox{Normal}(\mu^{e}_{t},\sigma^{e}_{t})\\
c_{it}&\sim \mbox{Normal}(\mu^{c}_{t},\sigma^{c}_{t})\\
\mbox{\textbf{Model of Missingness (MoM)}}\\
m^{e}_{it}&\sim \mbox{Bernoulli}(\pi^{e}_{it})\\
\mbox{logit}(\pi^{e}_{it})&=\gamma^{e}_{0}+\delta^{e}e_{it}\\
m^{c}_{it}&\sim \mbox{Bernoulli}(\pi^{c}_{it})\\
\mbox{logit}(\pi^{c}_{it})&=\gamma^{c}_{0}\\
\end{align*}

In the MoA, \(e_{it}\) and \(c_{it}\) respectively represent the
effectiveness and cost variables, for each treatment arm \(t=1,2\) and
individual \(i=1,\ldots,N_{t}\). Both variables are assumed to be
independently normally distributed with mean and standard deviation
parameters indicated by (\(\mu^{e}_{t},\sigma^{e}_{t}\)) and
(\(\mu^{c}_{t},\sigma^{c}_{t}\)), respectively. In the MoM the
missingness indicators for the outcome variables \(m^{e}_{it}\) and
\(m^{c}_{it}\) are given a Bernoulli distribution whose parameters
\(\pi^{e}_{it}\) and \(\pi^{c}_{it}\) are functions of other MoM
parameters on the log-odds scale. Specifically, since we assumed a MNAR
mechanism for the effects, the corresponding missingness probabilities
in both arms are a function of the baseline parameter \(\gamma^{e}_{0}\)
and the MNAR parameter \(\delta^{e}\). Conversely, given the MCAR
assumption for costs, the corresponding MoM specification inlcudes only
the baseline parameter \(\gamma^{c}_{0}\).

Prior distributions are assigned to both MoA and MoM parameters in a way
that is consitent with the description in Section \ref{MoA} and Section
\ref{MoM}, respectively. These can be represented as follows.

\begin{align*}
\hspace*{-5cm}
\mbox{\textbf{Prior Distributions (MoA)}}\\
\mu^{e}_{t}&\sim \mbox{Normal}(0,1000)\\
\mu^{c}_{t}&\sim \mbox{Normal}(0,1000)\\
\log(\sigma^{e}_{t})&\sim \mbox{Uniform}(-5,10)\\
\log(\sigma^{c}_{t})&\sim \mbox{Uniform}(-5,10)\\
\mbox{\textbf{Prior Distributions (MoM)}}\\
\gamma^{e}_{0}&\sim \mbox{Logistic}(0,1)\\
\delta^{e}_{0}&\sim \mbox{Normal}(0,1)\\
\gamma^{c}_{0}&\sim \mbox{Logistic}(0,1)
\end{align*}

In the MoA, weakly informative normal prior distributions centred at
\(0\) and with larger variances are assigned to mean paraemters, while
uniform distributions are assigned to standard deviation parameters on
the logarithm scale. In the MoM, standard logistic prior distributions
are assigned to the baseline parameters for both mechanisms to minimise
the informative impact on the probability scale. For the effects,
however, the assumed structure identified by the MNAR parameter
\(\delta^{e}\) highly depends on the corresponding hyper prior values
chosen. By default values are similar to those used for the mean
parameters in the MoA but, as explained in Section \ref{MoM}, users
should explore plausible priors according to the available information
so to assess the robustness of the results to alternative MNAR
structures.

This can be performed in \textbf{missingHE} by providing the prior
hyperparameter values desired by the users. For instance, for the
bivariate normal model example considered, priors for mean effect and
cost parameters can be modified by adding inside the function
\texttt{run\_model} the optional argument \texttt{prior} that should be
defined as a list. This list must contain a number of vectors equivalent
to the number of parameter classes whose prior we desire to change.
These vectors, in turn, must contain the hyperparameter values we want
to specificy and must comply with the prior forms assumed by
\textbf{missingHE} based on the type of MoA and MoM structure~assumed.

Returning to the example, if we want to change the priors of the mean
location parameter \(\mu^{e}\) and for the MNAR parameter \(\delta^{e}\)
we can do it by creating two objects named \texttt{mu.prior.e} and
\texttt{delta.prior.e} that contain the hyperprior values desired. In R
this can be performed as follows:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#hyperprior mean and standard deviation for the effect location parameter}
\NormalTok{a<-}\DecValTok{0}
\NormalTok{b<-}\DecValTok{1}
\NormalTok{mu.prior.e<-}\KeywordTok{c}\NormalTok{(a,b)}
\CommentTok{#hyperprior mean and standard deviation for the MNAR effect parameter}
\NormalTok{c<-}\DecValTok{0}
\NormalTok{d<-}\DecValTok{1}
\NormalTok{delta.prior.e<-}\KeywordTok{c}\NormalTok{(c,d)}
\end{Highlighting}
\end{Shaded}

Then, we must include these vectors inside a list object that is passed
as an additional argument, called \texttt{prior}, to the function
\texttt{run\_model}. It is important that such list object must contain
vector objects whose \textbf{string} names match those accepted by
\textbf{missingHE}. Using the hyperprior vectors created before, we can
proceed as follows:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{prior<-}\KeywordTok{list}\NormalTok{(}\StringTok{"mu.prior.e"}\NormalTok{=mu.prior.e,}\StringTok{"delta.prior.e"}\NormalTok{=delta.prior.e)}
\NormalTok{model<-}\KeywordTok{run_model}\NormalTok{(}\DataTypeTok{data=}\NormalTok{data,}\DataTypeTok{dist_e=}\StringTok{"norm"}\NormalTok{,}\DataTypeTok{dist_c=}\StringTok{"norm"}\NormalTok{,}\DataTypeTok{type=}\StringTok{"MNAR_eff"}\NormalTok{,}\DataTypeTok{stand=}\OtherTok{FALSE}\NormalTok{,}\DataTypeTok{ind=}\OtherTok{TRUE}\NormalTok{,}
                 \DataTypeTok{program=}\StringTok{"JAGS"}\NormalTok{,}\DataTypeTok{forward=}\OtherTok{FALSE}\NormalTok{,}\DataTypeTok{prob=}\KeywordTok{c}\NormalTok{(}\FloatTok{0.05}\NormalTok{,}\FloatTok{0.95}\NormalTok{),}\DataTypeTok{n.chains=}\DecValTok{2}\NormalTok{,}\DataTypeTok{n.iter=}\DecValTok{20000}\NormalTok{,}
                 \DataTypeTok{n.burnin=}\KeywordTok{floor}\NormalTok{(}\DecValTok{20000}\NormalTok{/}\DecValTok{2}\NormalTok{),}\DataTypeTok{inits=}\OtherTok{NULL}\NormalTok{,}\DataTypeTok{n.thin=}\DecValTok{1}\NormalTok{,}\DataTypeTok{save_model=}\OtherTok{FALSE}\NormalTok{,}\DataTypeTok{prior=}\NormalTok{prior)}
\end{Highlighting}
\end{Shaded}

Executing the command above creates an object \texttt{model} in the
class \texttt{missingHE}, in which the results of the economic analysis
are stored for the given MoA-MoM specification considered. The usual R
command

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{names}\NormalTok{(model)}
\end{Highlighting}
\end{Shaded}

returns the names of the elements in the list

\begin{verbatim}
## [1] "data_set"     "model_output" "cea"          "type"        
## [5] "model_class"
\end{verbatim}

The objects \texttt{data\_set}, \texttt{model\_output} and \texttt{cea}
are themselves lists that contain different elements related to the data
provided, the model results and the economic analysis, respectively. For
example, the elements in the first object can be accessed using the
standard R notation \texttt{model\$data\_set[]} (i.e.~using double
square brackets) and can be inspected typing the command

\begin{verbatim}
## [1] "effects"                      "costs"                       
## [3] "N in reference arm"           "N in comparator arm"         
## [5] "N observed in reference arm"  "N observed in comparator arm"
## [7] "N missing in reference arm"   "N missing in comparator arm" 
## [9] "covariates"
\end{verbatim}

These are merely the data related to the inputs given to the function
\texttt{run\_model}, such as effect and cost data, total number of
individuals in each arm, number of observed and unobserved individuals
in each arm and possible covariate data. The other elements of the
object \texttt{model} are

\begin{itemize}
\item
  \texttt{model\_output} is a list storing the output of the
  \texttt{BUGS} model. Depending on the type of model, the results shown
  in this list can vary as they contain the posterior samples of the
  parameters of interest either in the MoA and MoM or both (according to
  the MoA-MoM structure assumed). In the current example since a MNAR
  mechanism is assumed only for the effects, \texttt{model\_output}
  contains the posterior samples for \(\delta^{e}\) but does not contain
  any MoM parameters associated with the costs for which an ignorable
  mechanism was assumed (MCAR). \texttt{model\_output} also contains a
  summary of the \texttt{BUGS} model that is taken directly from the
  output of the functions in the package \textbf{R2OpenBUGS} or
  \textbf{R2jags} and which contain all the information related to the
  model.
\item
  \texttt{cea} is another list that stores the output of the economic
  evaluation based on the mean posterior samples of the mean effect and
  cost parameters and which is implemented using the functions in the
  package \textbf{BCEA}. This object can be analysed using tailored
  functions of \textbf{BCEA} to visually represent standard CEA outputs
  such as the Cost-Effectiveness Plane (CEP) \citep{Black} and the
  Cost-Acceptability Curve (CEAC) \citep{VanHout}.
\item
  \texttt{type} and \texttt{model\_class} are string variables that
  specify the type of mechanism assumed and sampling implemented,
  respectively.
\end{itemize}

\subsection{Model Convergence
Assessment}\label{model-convergence-assessment}

As with any MCMC estimation, it is important to thoroughly assess
convergence. The package \textbf{missingHE} contains the function
\texttt{diagnostic\_checks} to visualise the model output and assess
convergence. Different diagnostic tools and plots for the model
parameters are taken from the package \textbf{ggmcmc} and
\textbf{mcmcplots} and are displayed using functions from
\textbf{ggplot2} according to the inputs provided by the user. For
excample, considering the model output generated in \texttt{model} for
the current example, we can visually represent via histograms the
posterior samples for the mean effect parameters in the two arms in the
following way.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{check<-}\KeywordTok{diagnostic_checks}\NormalTok{(}\DataTypeTok{x=}\NormalTok{model,}\DataTypeTok{class=}\StringTok{"histogram"}\NormalTok{,}\DataTypeTok{parm=}\StringTok{"mu.e"}\NormalTok{,}\DataTypeTok{theme=}\OtherTok{NULL}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

which displays the graph in Figure \ref{fig:fig2}.

\begin{figure}[H]

{\centering \includegraphics{missingHE_files/figure-latex/checksplot-1} 

}

\caption{\label{fig:fig2}Checking model convergence using the \textbf{ggmcmc} package built-in facilities, for example through the inspection of the histogram plots by treatment arm for the mean effect parameters.}\label{fig:checksplot}
\end{figure}

The function \texttt{diagnostic\_checks} takes as compulsory input
\texttt{x} that must be an object of class \texttt{misisngHE}, such as
the object \texttt{model} generated by the function \texttt{run\_model}.
All other inputs are optional and are mainly used for selecting the
parameters of interest and for graphics changes. Among these the most
important are:

\begin{itemize}
\item
  \texttt{class} specifies the type of diagnostic tools to use for
  assessing convergence of the MCMC algorithm. A variety of plots are
  available such as histograms (\texttt{histogram}), density plots
  (\texttt{denplot}), traceplot (\texttt{traceplot}), autocorrelation
  plots (\texttt{autocorrplot}), etc. The full list of all available
  types of plots can be found in the package manual. In addition, the
  class \texttt{summary} can be selected to display a summary of some of
  the most important diagnostic plots for each parameter selected.
\item
  \texttt{parm} specifies for which family of model parameters the
  diagnostic output should be displayed and must correspond to a string
  variable among a set of pre-defined choices. Specifically, the mean
  effect or cost parameters in the MoA can be assessed via the
  expressions ``mu.e'' and ``mu.c'', respectively. If a MNAR mechanism
  is assumed, then also the MoM parameters can be assessed; for
  instance, in our example, we can select the MNAR parameter for the MoM
  in the effect variables via the expression ``delta.e''. Only one
  family of parameters can be visualied at a time. A family of
  parameters is defined to be any group of parameters with the same name
  but different numerical values between square brackets (as
  beta{[}1{]}, beta{[}2{]}, etc). The list of all parameters that can be
  specified with the corresponding string names to be used in
  \texttt{parm} can be found in the package manual. Alternatively, the
  set of all model parameters can be accessed by setting
  \texttt{parm="all"}, which also is the default value.
\item
  \texttt{theme} is merely a graphical argument which modifies the
  pre-defnied background theme of the plots generated. Pre-defined
  themes are taken from the package \textbf{ggthemes} and must be
  indicated with corresponding expressions. Examples are ``base'',
  ``calc'', ``economist'', etc. For a full list of available themes see
  the package manual.
\end{itemize}

It is also possible to combine multiple graphs by running
\texttt{diagnistic\_checks} different times, setting different
parameters to monitor, and save the plots in corresponding R objects. We
can then combine different plots into a single one using the function
\texttt{grid.arrange} from the \textbf{gridExtra} package (that should
be loaded). For example, we can combine the density and trace plots for
the mean effect parameters in the following way.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{require}\NormalTok{(gridExtra)}
\NormalTok{dens_eff<-}\KeywordTok{diagnostic_checks}\NormalTok{(}\DataTypeTok{x=}\NormalTok{model,}\DataTypeTok{class =} \StringTok{"denplot"}\NormalTok{,}\DataTypeTok{parm =} \StringTok{"mu.e"}\NormalTok{)}
\NormalTok{autoc_eff<-}\KeywordTok{diagnostic_checks}\NormalTok{(}\DataTypeTok{x=}\NormalTok{model,}\DataTypeTok{class =} \StringTok{"traceplot"}\NormalTok{,}\DataTypeTok{parm =} \StringTok{"mu.e"}\NormalTok{)}
\KeywordTok{grid.arrange}\NormalTok{(dens_eff$plot, autoc_eff$plot, }\DataTypeTok{ncol=}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

which returns the graphs in Figure \ref{fig:fig3}.

\begin{figure}[H]

{\centering \includegraphics{missingHE_files/figure-latex/finalplot-1} 

}

\caption{\label{fig:fig3}Combining different types of diagnostic check plots into a single one using the function \texttt{grid.arrange} in the package \textbf{gridExtra}. For example, here the density and trace plots for the mean effect parameters in the two arms are combined.}\label{fig:finalplot}
\end{figure}

\subsection{Summarising the Results from
MissingHE}\label{summarising-the-results-from-missinghe}

Objects in the class \texttt{missingHE} (such as \texttt{model} above)
can access methods such as \texttt{summary} and \texttt{plot} that can
be used to summarise the economic results and visually inspect how
missing data have been imputed in the model analysed.

\subsubsection{Missing Data Plots}\label{missing-data-plots}

Once the model have been estimated, we can visually inspect how missing
data in the outcome variables have been imputed and compare them to the
observed data. \textbf{MisisngHE} has a specialised function
\texttt{plot} that can do this, by typing:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(}\DataTypeTok{x=}\NormalTok{model,}\DataTypeTok{class=}\StringTok{"scatter"}\NormalTok{,}\DataTypeTok{outcome=}\StringTok{"all"}\NormalTok{,}\DataTypeTok{theme=}\StringTok{"base"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

which displays the graphs shown in Figure \ref{fig:fig4}.

\begin{figure}[H]

{\centering \includegraphics{missingHE_files/figure-latex/plotmissing-1} 

}

\caption{\label{fig:fig4}Comparing the observed and imputed effect and cost values in both treatment arms. Observed data are indicated with black dots while imputations are denoted by red dots and lines that define the credible intervals associated.}\label{fig:plotmissing}
\end{figure}

The only compulsory argument to be provided (\texttt{x}) is the
\texttt{missingHE} object containing the results from the function
\texttt{run\_model}. All the other arguments are optional and are mainly
related to the type of plot to be shown, which outcome and treatment arm
to consider, and other graphics parameters. For a complete list of all
arguments we refer to the package manual. Here we focus on two of the
most important:

\begin{itemize}
\item
  \texttt{class} specifies the type of plot to be displayed. Two
  alternatives are available: ``scatter'' and ``histogram''. Choosing
  ``scatter'' the observed and imputed values (evaluated at the
  posterior means) are shown in a scatter plot, with unobserved data
  also associated with lines representing their posterior credible
  intervals. By default these are the 95\% CI but they can also be
  modified by changing the values for the upper and lower bounds using
  the \texttt{prob} argument in the function \texttt{run\_model}.
  Setting ``histogram'' we compare the observed and missing values in a
  histogram plot and associate them with different colours.
\item
  \texttt{outcome} specifies for which variable, either effects, costs
  or both, and for which treatment arm, either control, intervention or
  both, results should be visualised. For example, the plots only for
  the effects (costs) can be selected setting \texttt{outcome} equal to
  ``effects'' (``costs''), while the plots by treatment arm can be
  accessed setting \texttt{outcome} equal to ``arm1'' (control) or
  ``arm2'' (intervention). Plots for each combination of outcome and
  treatment group can also be specified using the string names
  ``effects\_arm1'',``costs\_arm1'',``effects\_arm2'' or
  ``costs\_arm2''. By default all plots are displayed using the string
  name ``all''.
\item
  \texttt{theme} modifies the graphical output according to some
  pre-specified themes similarly to what shown for the
  \texttt{diagnostic\_checks} function.
\end{itemize}

\subsection{Summary CEA results}\label{summary-cea-results}

Results from the economic evaluation performed by \textbf{missingHE} in
the background can be summarised in a tabular form using the specialised
function \texttt{summary} by typing:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{summary<-}\KeywordTok{summary}\NormalTok{(}\DataTypeTok{x=}\NormalTok{model)}
\end{Highlighting}
\end{Shaded}

which returns the following table:

\begin{verbatim}
## 
##  Cost-effectiveness analysis summary 
##  
##  Comparator intervention: intervention 1 
##  Reference intervention: intervention 2 
##  
##  Model of Analysis (MoA) parameter estimates under MNAR_eff assumption
##  
##  Comparator intervention 
##                mean    sd     LB     UB
## mean effects  0.473 0.111  0.306  0.665
## mean costs   90.289 2.082 86.924 93.751
## sd effects    0.568 0.051  0.494  0.661
## sd costs     22.214 1.472 19.955 24.762
## 
##  Reference intervention 
##                 mean    sd     LB      UB
## mean effects   0.427 0.152  0.193   0.687
## mean costs   102.193 2.644 97.845 106.484
## sd effects      0.53 0.072  0.434   0.667
## sd costs      21.551 1.933 18.642   24.96
## 
##  Incremental results 
##                   mean    sd     LB     UB
## delta effects   -0.046 0.093 -0.202  0.106
## delta costs     11.904 3.364  6.367 17.385
## ICER          -260.259
\end{verbatim}

The only argument that must be provided is the object \texttt{x}
containing the results from the function \texttt{run\_model}.
Information is reported only for the main parameters of interest in the
MoA for performing the economic evaluation, that is the mean and
standard deviation parameters for both outcomes and treatment groups. In
addition, the incremental mean results are provided at the bottom of the
table, denoted with \texttt{delta effects} and \texttt{delta costs}
respectively, with also the value of the ICER. Results are summarised in
terms of posterior mean, standard deviation and 95\% credible intervals
for each parameter

A series of useful functions are included in the package \textbf{BCEA}
that summarise the economic evaluation results obtained from the
posterior samples of the mean effect and cost paraemters. Figure
\ref{fig:fig5} shows as an example the CEP and CEAC plots obtained from
applying the respective functions \texttt{ceac.plot} and
\texttt{ceplane.plot} to the \texttt{BCEA} object contained in
\texttt{model} and that can be accessed via \texttt{model\$cea}. The R
commands used to generate and combine these plots are the following.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{require}\NormalTok{(ggplot2)}
\KeywordTok{require}\NormalTok{(BCEA)}
\KeywordTok{ceac.plot}\NormalTok{(model$cea,}\DataTypeTok{graph =} \StringTok{"ggplot2"}\NormalTok{)+}\KeywordTok{ggtitle}\NormalTok{(}\StringTok{"CEAC"}\NormalTok{)}
\KeywordTok{ceplane.plot}\NormalTok{(model$cea,}\DataTypeTok{graph =} \StringTok{"ggplot2"}\NormalTok{)+}\KeywordTok{ggtitle}\NormalTok{(}\StringTok{"CEP"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

and the resulting output is given in Figure \ref{fig:fig5}

\begin{figure}[H]

{\centering \includegraphics[width=8cm,height=8cm]{missingHE_files/figure-latex/BCEAplot-1}
\centering \includegraphics[width=8cm,height=8cm]{missingHE_files/figure-latex/BCEAplot-2} 
}

\caption{\label{fig:fig5}Cost Effectiveness Acceptability Curve (CEAC) and Cost-Effectiveness Plane (CEP) obtained using respectively the function \texttt{ceac.plot} and \texttt{ceplane.plot} in the package \textbf{BCEA} and applied to the model results contained in the object model}\label{fig:BCEAplot1}
\end{figure}

\renewcommand\refname{References}
\bibliography{bibliography}


\end{document}
